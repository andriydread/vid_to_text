{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mock in /home/dread/miniconda3/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: pytube in /home/dread/miniconda3/lib/python3.12/site-packages (15.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U mock pytube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import mock\n",
    "\n",
    "from pytube.cipher import get_throttling_function_code\n",
    "\n",
    "def patched_throttling_plan(js: str):\n",
    "    \"\"\"Patch throttling plan, from https://github.com/pytube/pytube/issues/1498\"\"\"\n",
    "    raw_code = get_throttling_function_code(js)\n",
    "\n",
    "    transform_start = r\"try{\"\n",
    "    plan_regex = re.compile(transform_start)\n",
    "    match = plan_regex.search(raw_code)\n",
    "\n",
    "    #transform_plan_raw = find_object_from_startpoint(raw_code, match.span()[1] - 1)\n",
    "    transform_plan_raw = js\n",
    "\n",
    "    # Steps are either c[x](c[y]) or c[x](c[y],c[z])\n",
    "    step_start = r\"c\\[(\\d+)\\]\\(c\\[(\\d+)\\](,c(\\[(\\d+)\\]))?\\)\"\n",
    "    step_regex = re.compile(step_start)\n",
    "    matches = step_regex.findall(transform_plan_raw)\n",
    "    transform_steps = []\n",
    "    for match in matches:\n",
    "        if match[4] != '':\n",
    "            transform_steps.append((match[0],match[1],match[4]))\n",
    "        else:\n",
    "            transform_steps.append((match[0],match[1]))\n",
    "\n",
    "    return transform_steps\n",
    "\n",
    "\n",
    "with mock.patch('pytube.cipher.get_throttling_plan', patched_throttling_plan):\n",
    "    from pytube import YouTube\n",
    "\n",
    "    url = 'https://www.youtube.com/watch?v=VIR46oH-ufk&ab_channel=Horses'\n",
    "\n",
    "    video = YouTube(url)\n",
    "    audio = video.streams.filter(only_audio=True, file_extension='mp4')[0]\n",
    "    audio.download(filename='horses.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /home/dread/miniconda3/lib/python3.12/site-packages (20231117)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: numba in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (0.59.1)\n",
      "Requirement already satisfied: numpy in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/dread/miniconda3/lib/python3.12/site-packages (from openai-whisper) (0.6.0)\n",
      "Requirement already satisfied: filelock in /home/dread/miniconda3/lib/python3.12/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.4)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/dread/miniconda3/lib/python3.12/site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/dread/miniconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2024.4.16)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dread/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dread/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dread/miniconda3/lib/python3.12/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai-whisper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dread/miniconda3/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\")\n",
    "text = model.transcribe('horses.mp4')\n",
    "\n",
    "with open('text.txt', 'w') as f:\n",
    "    f.write(text[\"text\"])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The owner of this GPU was recently offered $15,000. In the next few years, the is for fruits of the and the first one was the first one. The first one was the first one. The first one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. The third one was the third one. In the same way, we are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see the same way. We are going to see what happens based on what happens. So this is going to find out which key work you are going to do in the first game. We're going to have one or later just a little while now. There is a better aim when they live. I think that the people who are in the world are not going to be able to do this. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think that it's a good thing to do. I think it's an aggressive thing to do. I think that it's a good thing to do. I think that it's a good thing to do. That's a weird thing to do. It's a very good place to go. See, the other thing is that the most common one is the the most common one. It's the most common one. The most common one is the the most common one. The most common one is the the most common one. The most common one is the the most common one. The most common one is the the most common one. The most common one is the the most common one is the the most common one is the the most common one is the the most common one is the the most common one is the the most common one is the most common one mas grab left left right East that one go with027, this will happenFC, etc lesions the edges, and those that are really of fiber Evenowmings ahead, photoph aid will become more flexible75 Unless he39 is much more successful than heael for other people Maybe he help Siren behave Definitely less of just the concern of it Very EW, I haven't given him something organised recognising It's a bitbe of concern P The first thing I want to do is to make a video of the video of the video of the video. I want to make a video of the video of the video of the video of the video of the video. I want to make a video of the video of the video of the video of the video of the video. I want to make a video of the video of the video of the video of the video of the video. Really talented guys, we want to all of the video of the video for... No talk! IostaILY Masu de tan linto Psylo Que coutaba Santos Mayle Was a lovelyet Masi commercial I also a pretend lady booths to visit the hotel o Longra could tell me that I was an artist because I got a big surprise Let's try Which is a Jazz You alwaysbedroom That that was the house And Detroit I will return toof approximately You've come 6 days I have a great time Prior to the Living We are making and�, and we found our car tempting in place itself, and the most important thing is the the most important thing. In the same moment, the most important thing is the most important thing. The most important thing is the most important thing. The most important thing is the most important thing. The most important thing is the most important thing. The most important thing is the most important thing is the most important thing is the most important thing is when most important enough is the most important. However, the next thing is the least important Along the main set of basic moments to this enemy's Trapar will be avoided and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and the most important hardware, and especially, and in reality, we also filmed a fundraiser for weekly stimulus of the regular ecosystem, and the studio... this process of a new bit, are often the Increase Don could make a story called you in the mix of types you wishupcycle this to use the foundation that Ice turned off in the mix of Ammon's Air then firstly the objective, that kind acts like g That's the first time we joined Main unprepared. For example, saw our the physical volcanic water conventional andUali Those there must berimps. In the pre-endale. The plant has evolved even more. During our trailer, along with the rest of the age in and the most important thing is that the world is not only the world, but the world is the most important thing to be the most important thing to be the most important thing to be the most important thing is the world's most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing to be the most important thing is to champion the newer 111 and them toowa. This was the work of Kevin Kineros worked as doing some great work at the bottom of Mexico Almost the proper So, we are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. We are going to see the first one. Now, we are currently crypt47eos. I am sitting on the lim to order because we are going to see or get a little bit black, so they can't realize where the colours are from. The first one is white. We are just going to see the first one. We are going to see the other ones. We want that ... In this case this was a little bit red on implement. The one with the little fill is brown and purple, which will be around the space, and to know whether it's just Android collection. Then we need the green brandl so we also want to see the first one. We also use a different side. Well, thank you for again.\n"
     ]
    }
   ],
   "source": [
    "content = open('text.txt', 'r').read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/dread/miniconda3/lib/python3.12/site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain_openai in /home/dread/miniconda3/lib/python3.12/site-packages (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (0.1.46)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain_openai) (1.23.6)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dread/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dread/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dread/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/dread/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/dread/miniconda3/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/dread/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/dread/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/dread/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dread/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/dread/miniconda3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/dread/miniconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2024.4.16)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dread/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/dread/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/dread/miniconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Installs langchain libraries\n",
    "! pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    # template=\"\"\"Create 3 separate paragraphs based on this text, start the first paragraph with the words /\n",
    "    # 'The idea of ​​this text...' and make it one sentence long, start second paragraph with 'Content of this text...' and provide shortened version of originat provided text, make it at least 8 sentences long,\n",
    "    # in the third paragraph give me 4 simple statements in numbered list form based on of this text. Text ====== {text}\"\"\",\n",
    "    template= \"\"\"\n",
    "        Review this text and summarize it -----{text}\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "with open('response.txt', 'w') as f:\n",
    "    f.write(chain.invoke(content))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4444/2204574779.py:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file('response.mp4')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "response = client.audio.speech.create(\n",
    "    model = 'tts-1',\n",
    "    voice = 'echo',\n",
    "    input = open('response.txt', 'r').read()\n",
    ")\n",
    "response.stream_to_file('response.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
